{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Long datasets taking too much time for training\n",
        "# so im using sort 350 line dataset"
      ],
      "metadata": {
        "id": "XODT3bCgfagl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nheg7iBIfIa1"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "hello how are you\n",
        "i am good thank you\n",
        "what are you doing\n",
        "just watching a movie\n",
        "which movie are you watching\n",
        "i am watching inception\n",
        "oh that is a great movie\n",
        "yes it really is\n",
        "do you like science fiction\n",
        "yes i love sci fi movies\n",
        "who is your favorite actor\n",
        "i really like leonardo dicaprio\n",
        "he is a great actor\n",
        "what is your plan for today\n",
        "Let’s plan a small road trip next weekend together.\n",
        "My sister is coming home for the summer vacation.\n",
        "She cooked a delicious meal for the whole family yesterday.\n",
        "He spends most of his weekends reading fantasy novels alone.\n",
        "They went hiking in the forest near the waterfall trail.\n",
        "I really enjoy long conversations under the night sky.\n",
        "We’ve been working on this group project for weeks.\n",
        "The teacher asked us to submit the report tomorrow.\n",
        "He wants to become a software developer in the future.\n",
        "I like starting my day with a morning walk.\n",
        "She made a chocolate cake for her brother’s birthday.\n",
        "Let’s meet at the park around six in the evening.\n",
        "This winter has been colder than the previous few years.\n",
        "i am going to study\n",
        "what are you studying\n",
        "i have a math test tomorrow\n",
        "good luck with your test\n",
        "thank you so much\n",
        "what time is your test\n",
        "it is at ten in the morning\n",
        "do you feel prepared\n",
        "yes i studied a lot\n",
        "that is great to hear\n",
        "have you had breakfast\n",
        "not yet i am going to eat soon\n",
        "what will you eat\n",
        "probably eggs and toast\n",
        "sounds delicious\n",
        "what about you\n",
        "i already had breakfast\n",
        "what did you eat\n",
        "i had cereal and milk\n",
        "nice choice\n",
        "do you want to go for a walk\n",
        "sure that sounds nice\n",
        "let's meet at the park\n",
        "what time\n",
        "around five pm\n",
        "okay see you then\n",
        "see you soon\n",
        "how is your family\n",
        "they are all doing well\n",
        "that is good\n",
        "how about yours\n",
        "everyone is fine thanks\n",
        "did you watch the game last night\n",
        "no i missed it\n",
        "who won\n",
        "our team won\n",
        "amazing i am happy to hear that\n",
        "they played very well\n",
        "yes they are improving a lot\n",
        "did you finish your homework\n",
        "not yet i will do it after dinner\n",
        "make sure to finish on time\n",
        "i will\n",
        "what are your weekend plans\n",
        "i might visit my grandparents\n",
        "that sounds nice\n",
        "they live in the countryside\n",
        "i love the countryside\n",
        "yes it's peaceful there\n",
        "do you like to read books\n",
        "absolutely i enjoy reading\n",
        "what book are you reading now\n",
        "i just started a mystery novel\n",
        "who is the author\n",
        "agatha christie\n",
        "oh i love her books\n",
        "yes she is a great writer\n",
        "what is your favorite genre\n",
        "i like mystery and fantasy\n",
        "do you read every day\n",
        "i try to read before bed\n",
        "that is a good habit\n",
        "thank you\n",
        "do you have any pets\n",
        "yes i have a dog\n",
        "what is your dog's name\n",
        "his name is rocky\n",
        "cute name\n",
        "thank you\n",
        "do you take him for walks\n",
        "yes every evening\n",
        "he must love that\n",
        "yes he gets very excited\n",
        "dogs are so loyal\n",
        "i agree they are wonderful\n",
        "do you like cats too\n",
        "yes they are very cute\n",
        "do you prefer tea or coffee\n",
        "i like coffee in the morning\n",
        "same here\n",
        "do you work out\n",
        "yes i go to the gym\n",
        "how often\n",
        "about four times a week\n",
        "impressive\n",
        "thanks i am trying to stay fit\n",
        "that's a good goal\n",
        "do you listen to music\n",
        "all the time\n",
        "who is your favorite singer\n",
        "i really like taylor swift\n",
        "she has great songs\n",
        "yes i enjoy her music too\n",
        "what is your favorite song\n",
        "currently it's love story\n",
        "nice choice\n",
        "thank you\n",
        "are you free this weekend\n",
        "yes i am\n",
        "let's go hiking\n",
        "that sounds fun\n",
        "i will bring snacks\n",
        "great idea\n",
        "see you saturday\n",
        "see you then\n",
        "take care\n",
        "you too\n",
        "good night\n",
        "good night sweet dreams\n",
        "thank you\n",
        "have a great day\n",
        "you too bye\n",
        "bye see you tomorrow\n",
        "sure see you\n",
        "how was your day\n",
        "it was good and relaxing\n",
        "did you do anything special\n",
        "not really just rested\n",
        "sometimes rest is important\n",
        "i agree\n",
        "what time do you usually sleep\n",
        "around eleven pm\n",
        "that is healthy\n",
        "i try to sleep early\n",
        "same here\n",
        "do you like cooking\n",
        "yes it is fun\n",
        "what do you like to cook\n",
        "mostly pasta and rice\n",
        "do you cook often\n",
        "a few times a week\n",
        "that's nice\n",
        "thanks\n",
        "do you watch tv shows\n",
        "yes i love them\n",
        "what is your favorite show\n",
        "friends and stranger things\n",
        "great choices\n",
        "thank you\n",
        "what phone do you use\n",
        "i use an iphone\n",
        "how do you like it\n",
        "i love it\n",
        "me too\n",
        "okay i have to go now\n",
        "talk to you later\n",
        "sure bye\n",
        "are you going to the party\n",
        "yes i am excited\n",
        "who else is coming\n",
        "i think john and emma\n",
        "cool it will be fun\n",
        "yes looking forward to it\n",
        "what will you wear\n",
        "probably a blue shirt\n",
        "nice that will look good\n",
        "thanks for the compliment\n",
        "do you need a ride\n",
        "yes if it’s not a problem\n",
        "not at all happy to help\n",
        "what time should i pick you up\n",
        "around seven would be great\n",
        "perfect see you then\n",
        "see you soon\n",
        "do you like painting\n",
        "yes it helps me relax\n",
        "what do you paint\n",
        "mostly landscapes and flowers\n",
        "that sounds beautiful\n",
        "thank you\n",
        "do you take art classes\n",
        "i learned from youtube\n",
        "that’s impressive\n",
        "you can learn so much online\n",
        "yes internet is a great teacher\n",
        "what hobbies do you have\n",
        "i enjoy writing and drawing\n",
        "have you written stories\n",
        "yes short ones for fun\n",
        "you should publish them\n",
        "maybe one day\n",
        "you definitely should\n",
        "thank you for the encouragement\n",
        "how do you deal with stress\n",
        "i usually go for a walk\n",
        "that helps me too\n",
        "fresh air is amazing\n",
        "yes and nature calms me\n",
        "do you practice meditation\n",
        "sometimes before sleeping\n",
        "it helps clear the mind\n",
        "yes and improves focus\n",
        "have you tried yoga\n",
        "a few times yes\n",
        "did you like it\n",
        "yes it's very refreshing\n",
        "i should try it again\n",
        "you definitely should\n",
        "do you like learning languages\n",
        "yes i want to learn spanish\n",
        "that's a good choice\n",
        "it's a beautiful language\n",
        "i agree\n",
        "I’ve been practicing yoga every day for inner peace.\n",
        "The new smartphone model comes out in two more weeks.\n",
        "We discussed our weekend plans during the lunch break today.\n",
        "Do you remember where we parked the car last night?\n",
        "She watched the entire season of the show in one day.\n",
        "He’s trying to improve his English by reading every night.\n",
        "We stayed up late watching horror movies and eating snacks.\n",
        "He’s thinking about joining a guitar class this summer.\n",
        "I need to finish this project before the deadline tomorrow.\n",
        "She always helps others whenever they are in need.\n",
        "My parents are planning to renovate our house next month.\n",
        "We forgot to bring the tickets to the music event.\n",
        "how are your classes going\n",
        "they are going well\n",
        "what subject is your favorite\n",
        "i enjoy computer science\n",
        "me too it’s fascinating\n",
        "do you code often\n",
        "yes i practice daily\n",
        "that’s awesome\n",
        "practice makes perfect\n",
        "do you know python\n",
        "yes it's my favorite language\n",
        "mine too\n",
        "what projects have you built\n",
        "a few simple games and apps\n",
        "that's really cool\n",
        "thank you\n",
        "do you want to work in tech\n",
        "yes it’s my dream job\n",
        "you will get there\n",
        "thank you for believing in me\n",
        "do you use github\n",
        "yes for all my projects\n",
        "that’s smart\n",
        "it keeps everything organized\n",
        "yes and shows progress\n",
        "do you use stackoverflow\n",
        "yes all the time\n",
        "same it’s a lifesaver\n",
        "definitely\n",
        "how do you stay motivated\n",
        "i set small goals\n",
        "that's a great strategy\n",
        "thank you\n",
        "do you follow a schedule\n",
        "i try to but not always\n",
        "same here it's hard sometimes\n",
        "yes but consistency matters\n",
        "very true\n",
        "what do you do when bored\n",
        "i watch youtube or read\n",
        "same here\n",
        "I am planning a trip to the mountains tomorrow.\n",
        "Do you want to join us for dinner tonight?\n",
        "She always listens to music while doing her homework.\n",
        "He bought a new laptop for college last week.\n",
        "I am learning Python to build cool machine learning projects.\n",
        "My friends and I are going shopping this weekend.\n",
        "The exam was harder than I expected it to be.\n",
        "We should definitely meet up sometime during the holidays.\n",
        "She enjoys painting flowers and landscapes in her free time.\n",
        "I need to buy groceries before the store closes tonight.\n",
        "He goes to the gym almost every single morning.\n",
        "Would you like to grab coffee after your class?\n",
        "I heard there’s a new movie releasing this Friday.\n",
        "She wore a beautiful dress to the party last night.\n",
        "He fixed the bug in the code after debugging carefully.\n",
        "My cousin is visiting us from Delhi next Thursday morning.\n",
        "They are planning a surprise birthday party for their friend.\n",
        "The dog chased the ball across the backyard very quickly.\n",
        "We enjoyed the concert even though it was raining outside.\n",
        "He missed the train because he woke up too late.\n",
        "She talks about her cat in every single conversation.\n",
        "We should try that new Italian restaurant this Saturday evening.\n",
        "He joined the workshop to learn data visualization techniques.\n",
        "Our team is meeting at the cafe after the match.\n",
        "I found a great online course about artificial intelligence basics.\n",
        "sometimes i clean my room\n",
        "that’s productive\n",
        "do you play games\n",
        "yes sometimes on weekends\n",
        "what kind of games\n",
        "mostly strategy and puzzles\n",
        "sounds fun\n",
        "it is very engaging\n",
        "do you prefer indoor or outdoor games\n",
        "i like both\n",
        "do you go cycling\n",
        "yes in the morning\n",
        "healthy habit\n",
        "thank you\n",
        "do you like photography\n",
        "yes especially nature shots\n",
        "me too\n",
        "do you use a camera or phone\n",
        "mostly phone\n",
        "phones take great pictures these days\n",
        "yes technology has improved a lot\n",
        "absolutely\n",
        "what social media do you use\n",
        "mainly instagram\n",
        "same here\n",
        "do you post often\n",
        "not really just stories\n",
        "do you follow celebrities\n",
        "a few for updates\n",
        "makes sense\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "cR8RUxHKhcG-",
        "outputId": "4084c73c-b3b2-49e9-a9d1-c57ca20e2a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nhello how are you\\ni am good thank you\\nwhat are you doing\\njust watching a movie\\nwhich movie are you watching\\ni am watching inception\\noh that is a great movie\\nyes it really is\\ndo you like science fiction\\nyes i love sci fi movies\\nwho is your favorite actor\\ni really like leonardo dicaprio\\nhe is a great actor\\nwhat is your plan for today\\nLet’s plan a small road trip next weekend together.\\nMy sister is coming home for the summer vacation.\\nShe cooked a delicious meal for the whole family yesterday.\\nHe spends most of his weekends reading fantasy novels alone.\\nThey went hiking in the forest near the waterfall trail.\\nI really enjoy long conversations under the night sky.\\nWe’ve been working on this group project for weeks.\\nThe teacher asked us to submit the report tomorrow.\\nHe wants to become a software developer in the future.\\nI like starting my day with a morning walk.\\nShe made a chocolate cake for her brother’s birthday.\\nLet’s meet at the park around six in the evening.\\nThis winter has been colder than the previous few years.\\ni am going to study\\nwhat are you studying\\ni have a math test tomorrow\\ngood luck with your test\\nthank you so much\\nwhat time is your test\\nit is at ten in the morning\\ndo you feel prepared\\nyes i studied a lot\\nthat is great to hear\\nhave you had breakfast\\nnot yet i am going to eat soon\\nwhat will you eat\\nprobably eggs and toast\\nsounds delicious\\nwhat about you\\ni already had breakfast\\nwhat did you eat\\ni had cereal and milk\\nnice choice\\ndo you want to go for a walk\\nsure that sounds nice\\nlet's meet at the park\\nwhat time\\naround five pm\\nokay see you then\\nsee you soon\\nhow is your family\\nthey are all doing well\\nthat is good\\nhow about yours\\neveryone is fine thanks\\ndid you watch the game last night\\nno i missed it\\nwho won\\nour team won\\namazing i am happy to hear that\\nthey played very well\\nyes they are improving a lot\\ndid you finish your homework\\nnot yet i will do it after dinner\\nmake sure to finish on time\\ni will\\nwhat are your weekend plans\\ni might visit my grandparents\\nthat sounds nice\\nthey live in the countryside\\ni love the countryside\\nyes it's peaceful there\\ndo you like to read books\\nabsolutely i enjoy reading\\nwhat book are you reading now\\ni just started a mystery novel\\nwho is the author\\nagatha christie\\noh i love her books\\nyes she is a great writer\\nwhat is your favorite genre\\ni like mystery and fantasy\\ndo you read every day\\ni try to read before bed\\nthat is a good habit\\nthank you\\ndo you have any pets\\nyes i have a dog\\nwhat is your dog's name\\nhis name is rocky\\ncute name\\nthank you\\ndo you take him for walks\\nyes every evening\\nhe must love that\\nyes he gets very excited\\ndogs are so loyal\\ni agree they are wonderful\\ndo you like cats too\\nyes they are very cute\\ndo you prefer tea or coffee\\ni like coffee in the morning\\nsame here\\ndo you work out\\nyes i go to the gym\\nhow often\\nabout four times a week\\nimpressive\\nthanks i am trying to stay fit\\nthat's a good goal\\ndo you listen to music\\nall the time\\nwho is your favorite singer\\ni really like taylor swift\\nshe has great songs\\nyes i enjoy her music too\\nwhat is your favorite song\\ncurrently it's love story\\nnice choice\\nthank you\\nare you free this weekend\\nyes i am\\nlet's go hiking\\nthat sounds fun\\ni will bring snacks\\ngreat idea\\nsee you saturday\\nsee you then\\ntake care\\nyou too\\ngood night\\ngood night sweet dreams\\nthank you\\nhave a great day\\nyou too bye\\nbye see you tomorrow\\nsure see you\\nhow was your day\\nit was good and relaxing\\ndid you do anything special\\nnot really just rested\\nsometimes rest is important\\ni agree\\nwhat time do you usually sleep\\naround eleven pm\\nthat is healthy\\ni try to sleep early\\nsame here\\ndo you like cooking\\nyes it is fun\\nwhat do you like to cook\\nmostly pasta and rice\\ndo you cook often\\na few times a week\\nthat's nice\\nthanks\\ndo you watch tv shows\\nyes i love them\\nwhat is your favorite show\\nfriends and stranger things\\ngreat choices\\nthank you\\nwhat phone do you use\\ni use an iphone\\nhow do you like it\\ni love it\\nme too\\nokay i have to go now\\ntalk to you later\\nsure bye\\nare you going to the party\\nyes i am excited\\nwho else is coming\\ni think john and emma\\ncool it will be fun\\nyes looking forward to it\\nwhat will you wear\\nprobably a blue shirt\\nnice that will look good\\nthanks for the compliment\\ndo you need a ride\\nyes if it’s not a problem\\nnot at all happy to help\\nwhat time should i pick you up\\naround seven would be great\\nperfect see you then\\nsee you soon\\ndo you like painting\\nyes it helps me relax\\nwhat do you paint\\nmostly landscapes and flowers\\nthat sounds beautiful\\nthank you\\ndo you take art classes\\ni learned from youtube\\nthat’s impressive\\nyou can learn so much online\\nyes internet is a great teacher\\nwhat hobbies do you have\\ni enjoy writing and drawing\\nhave you written stories\\nyes short ones for fun\\nyou should publish them\\nmaybe one day\\nyou definitely should\\nthank you for the encouragement\\nhow do you deal with stress\\ni usually go for a walk\\nthat helps me too\\nfresh air is amazing\\nyes and nature calms me\\ndo you practice meditation\\nsometimes before sleeping\\nit helps clear the mind\\nyes and improves focus\\nhave you tried yoga\\na few times yes\\ndid you like it\\nyes it's very refreshing\\ni should try it again\\nyou definitely should\\ndo you like learning languages\\nyes i want to learn spanish\\nthat's a good choice\\nit's a beautiful language\\ni agree\\nI’ve been practicing yoga every day for inner peace.\\nThe new smartphone model comes out in two more weeks.\\nWe discussed our weekend plans during the lunch break today.\\nDo you remember where we parked the car last night?\\nShe watched the entire season of the show in one day.\\nHe’s trying to improve his English by reading every night.\\nWe stayed up late watching horror movies and eating snacks.\\nHe’s thinking about joining a guitar class this summer.\\nI need to finish this project before the deadline tomorrow.\\nShe always helps others whenever they are in need.\\nMy parents are planning to renovate our house next month.\\nWe forgot to bring the tickets to the music event.\\nhow are your classes going\\nthey are going well\\nwhat subject is your favorite\\ni enjoy computer science\\nme too it’s fascinating\\ndo you code often\\nyes i practice daily\\nthat’s awesome\\npractice makes perfect\\ndo you know python\\nyes it's my favorite language\\nmine too\\nwhat projects have you built\\na few simple games and apps\\nthat's really cool\\nthank you\\ndo you want to work in tech\\nyes it’s my dream job\\nyou will get there\\nthank you for believing in me\\ndo you use github\\nyes for all my projects\\nthat’s smart\\nit keeps everything organized\\nyes and shows progress\\ndo you use stackoverflow\\nyes all the time\\nsame it’s a lifesaver\\ndefinitely\\nhow do you stay motivated\\ni set small goals\\nthat's a great strategy\\nthank you\\ndo you follow a schedule\\ni try to but not always\\nsame here it's hard sometimes\\nyes but consistency matters\\nvery true\\nwhat do you do when bored\\ni watch youtube or read\\nsame here\\nI am planning a trip to the mountains tomorrow.\\nDo you want to join us for dinner tonight?\\nShe always listens to music while doing her homework.\\nHe bought a new laptop for college last week.\\nI am learning Python to build cool machine learning projects.\\nMy friends and I are going shopping this weekend.\\nThe exam was harder than I expected it to be.\\nWe should definitely meet up sometime during the holidays.\\nShe enjoys painting flowers and landscapes in her free time.\\nI need to buy groceries before the store closes tonight.\\nHe goes to the gym almost every single morning.\\nWould you like to grab coffee after your class?\\nI heard there’s a new movie releasing this Friday.\\nShe wore a beautiful dress to the party last night.\\nHe fixed the bug in the code after debugging carefully.\\nMy cousin is visiting us from Delhi next Thursday morning.\\nThey are planning a surprise birthday party for their friend.\\nThe dog chased the ball across the backyard very quickly.\\nWe enjoyed the concert even though it was raining outside.\\nHe missed the train because he woke up too late.\\nShe talks about her cat in every single conversation.\\nWe should try that new Italian restaurant this Saturday evening.\\nHe joined the workshop to learn data visualization techniques.\\nOur team is meeting at the cafe after the match.\\nI found a great online course about artificial intelligence basics.\\nsometimes i clean my room\\nthat’s productive\\ndo you play games\\nyes sometimes on weekends\\nwhat kind of games\\nmostly strategy and puzzles\\nsounds fun\\nit is very engaging\\ndo you prefer indoor or outdoor games\\ni like both\\ndo you go cycling\\nyes in the morning\\nhealthy habit\\nthank you\\ndo you like photography\\nyes especially nature shots\\nme too\\ndo you use a camera or phone\\nmostly phone\\nphones take great pictures these days\\nyes technology has improved a lot\\nabsolutely\\nwhat social media do you use\\nmainly instagram\\nsame here\\ndo you post often\\nnot really just stories\\ndo you follow celebrities\\na few for updates\\nmakes sense\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "tVAYIAhSfvWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "nCqNt3MEgAHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk = Tokenizer(\n",
        "    lower=True, oov_token=None\n",
        ")"
      ],
      "metadata": {
        "id": "yAn98KDCgMOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "R81oGMVlgdDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tk.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2snQIydyguNY",
        "outputId": "dd09e375-e738-4fb3-a889-10ccd333b8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "580"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How you create dataset for training\n",
        "\n",
        "[23, 1 , 67 , 45] ---> first sentence\n",
        "\n",
        "# now the process of prediction is\n",
        "[23] -----> 1\n",
        "\n",
        "[23, 1] -----> 67\n",
        "\n",
        "[23, 1 , 67] ------> 45\n"
      ],
      "metadata": {
        "id": "2-vJNIGViu0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sents = []\n",
        "\n",
        "for sent in text.split('\\n'):\n",
        "  tokenize_sent = tk.texts_to_sequences([sent])[0]\n",
        "\n",
        "  for i in range(1,len(tokenize_sent)):\n",
        "    input_sents.append(tokenize_sent[:i+1])\n",
        "    # making pair like pahle me 2 number aayenge fir 3 fir 4......\n"
      ],
      "metadata": {
        "id": "zVBW-B48hqLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWEva9v6lbeD",
        "outputId": "449a188d-ce1c-436a-a207-aff7c4b10134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[227, 28],\n",
              " [227, 28, 10],\n",
              " [227, 28, 10, 1],\n",
              " [2, 21],\n",
              " [2, 21, 22],\n",
              " [2, 21, 22, 18],\n",
              " [2, 21, 22, 18, 1],\n",
              " [9, 10],\n",
              " [9, 10, 1],\n",
              " [9, 10, 1, 94],\n",
              " [67, 68],\n",
              " [67, 68, 5],\n",
              " [67, 68, 5, 69],\n",
              " [228, 69],\n",
              " [228, 69, 10],\n",
              " [228, 69, 10, 1],\n",
              " [228, 69, 10, 1, 68],\n",
              " [2, 21],\n",
              " [2, 21, 68],\n",
              " [2, 21, 68, 229],\n",
              " [134, 17],\n",
              " [134, 17, 8],\n",
              " [134, 17, 8, 5],\n",
              " [134, 17, 8, 5, 19],\n",
              " [134, 17, 8, 5, 19, 69],\n",
              " [7, 11],\n",
              " [7, 11, 33],\n",
              " [7, 11, 33, 8],\n",
              " [4, 1],\n",
              " [4, 1, 13],\n",
              " [4, 1, 13, 135],\n",
              " [4, 1, 13, 135, 230],\n",
              " [7, 2],\n",
              " [7, 2, 34],\n",
              " [7, 2, 34, 231],\n",
              " [7, 2, 34, 231, 232],\n",
              " [7, 2, 34, 231, 232, 136],\n",
              " [54, 8],\n",
              " [54, 8, 15],\n",
              " [54, 8, 15, 35],\n",
              " [54, 8, 15, 35, 137],\n",
              " [2, 33],\n",
              " [2, 33, 13],\n",
              " [2, 33, 13, 233],\n",
              " [2, 33, 13, 233, 234],\n",
              " [20, 8],\n",
              " [20, 8, 5],\n",
              " [20, 8, 5, 19],\n",
              " [20, 8, 5, 19, 137],\n",
              " [9, 8],\n",
              " [9, 8, 15],\n",
              " [9, 8, 15, 138],\n",
              " [9, 8, 15, 138, 12],\n",
              " [9, 8, 15, 138, 12, 139],\n",
              " [140, 138],\n",
              " [140, 138, 5],\n",
              " [140, 138, 5, 141],\n",
              " [140, 138, 5, 141, 235],\n",
              " [140, 138, 5, 141, 235, 142],\n",
              " [140, 138, 5, 141, 235, 142, 95],\n",
              " [140, 138, 5, 141, 235, 142, 95, 55],\n",
              " [140, 138, 5, 141, 235, 142, 95, 55, 236],\n",
              " [23, 237],\n",
              " [23, 237, 8],\n",
              " [23, 237, 8, 143],\n",
              " [23, 237, 8, 143, 238],\n",
              " [23, 237, 8, 143, 238, 12],\n",
              " [23, 237, 8, 143, 238, 12, 3],\n",
              " [23, 237, 8, 143, 238, 12, 3, 144],\n",
              " [23, 237, 8, 143, 238, 12, 3, 144, 239],\n",
              " [24, 240],\n",
              " [24, 240, 5],\n",
              " [24, 240, 5, 145],\n",
              " [24, 240, 5, 145, 241],\n",
              " [24, 240, 5, 145, 241, 12],\n",
              " [24, 240, 5, 145, 241, 12, 3],\n",
              " [24, 240, 5, 145, 241, 12, 3, 242],\n",
              " [24, 240, 5, 145, 241, 12, 3, 242, 146],\n",
              " [24, 240, 5, 145, 241, 12, 3, 242, 146, 243],\n",
              " [20, 244],\n",
              " [20, 244, 245],\n",
              " [20, 244, 245, 96],\n",
              " [20, 244, 245, 96, 97],\n",
              " [20, 244, 245, 96, 97, 147],\n",
              " [20, 244, 245, 96, 97, 147, 70],\n",
              " [20, 244, 245, 96, 97, 147, 70, 148],\n",
              " [20, 244, 245, 96, 97, 147, 70, 148, 246],\n",
              " [20, 244, 245, 96, 97, 147, 70, 148, 246, 247],\n",
              " [25, 248],\n",
              " [25, 248, 149],\n",
              " [25, 248, 149, 16],\n",
              " [25, 248, 149, 16, 3],\n",
              " [25, 248, 149, 16, 3, 249],\n",
              " [25, 248, 149, 16, 3, 249, 250],\n",
              " [25, 248, 149, 16, 3, 249, 250, 3],\n",
              " [25, 248, 149, 16, 3, 249, 250, 3, 251],\n",
              " [25, 248, 149, 16, 3, 249, 250, 3, 251, 252],\n",
              " [2, 33],\n",
              " [2, 33, 56],\n",
              " [2, 33, 56, 253],\n",
              " [2, 33, 56, 253, 254],\n",
              " [2, 33, 56, 253, 254, 255],\n",
              " [2, 33, 56, 253, 254, 255, 3],\n",
              " [2, 33, 56, 253, 254, 255, 3, 36],\n",
              " [2, 33, 56, 253, 254, 255, 3, 36, 256],\n",
              " [257, 98],\n",
              " [257, 98, 258],\n",
              " [257, 98, 258, 99],\n",
              " [257, 98, 258, 99, 29],\n",
              " [257, 98, 258, 99, 29, 259],\n",
              " [257, 98, 258, 99, 29, 259, 150],\n",
              " [257, 98, 258, 99, 29, 259, 150, 12],\n",
              " [257, 98, 258, 99, 29, 259, 150, 12, 151],\n",
              " [3, 152],\n",
              " [3, 152, 260],\n",
              " [3, 152, 260, 100],\n",
              " [3, 152, 260, 100, 6],\n",
              " [3, 152, 260, 100, 6, 261],\n",
              " [3, 152, 260, 100, 6, 261, 3],\n",
              " [3, 152, 260, 100, 6, 261, 3, 262],\n",
              " [3, 152, 260, 100, 6, 261, 3, 262, 57],\n",
              " [20, 263],\n",
              " [20, 263, 6],\n",
              " [20, 263, 6, 264],\n",
              " [20, 263, 6, 264, 5],\n",
              " [20, 263, 6, 264, 5, 265],\n",
              " [20, 263, 6, 264, 5, 265, 266],\n",
              " [20, 263, 6, 264, 5, 265, 266, 16],\n",
              " [20, 263, 6, 264, 5, 265, 266, 16, 3],\n",
              " [20, 263, 6, 264, 5, 265, 266, 16, 3, 267],\n",
              " [2, 13],\n",
              " [2, 13, 268],\n",
              " [2, 13, 268, 23],\n",
              " [2, 13, 268, 23, 37],\n",
              " [2, 13, 268, 23, 37, 101],\n",
              " [2, 13, 268, 23, 37, 101, 5],\n",
              " [2, 13, 268, 23, 37, 101, 5, 43],\n",
              " [2, 13, 268, 23, 37, 101, 5, 43, 102],\n",
              " [24, 269],\n",
              " [24, 269, 5],\n",
              " [24, 269, 5, 270],\n",
              " [24, 269, 5, 270, 271],\n",
              " [24, 269, 5, 270, 271, 12],\n",
              " [24, 269, 5, 270, 271, 12, 44],\n",
              " [24, 269, 5, 270, 271, 12, 44, 272],\n",
              " [24, 269, 5, 270, 271, 12, 44, 272, 153],\n",
              " [140, 103],\n",
              " [140, 103, 58],\n",
              " [140, 103, 58, 3],\n",
              " [140, 103, 58, 3, 154],\n",
              " [140, 103, 58, 3, 154, 71],\n",
              " [140, 103, 58, 3, 154, 71, 273],\n",
              " [140, 103, 58, 3, 154, 71, 273, 16],\n",
              " [140, 103, 58, 3, 154, 71, 273, 16, 3],\n",
              " [140, 103, 58, 3, 154, 71, 273, 16, 3, 104],\n",
              " [29, 274],\n",
              " [29, 274, 105],\n",
              " [29, 274, 105, 98],\n",
              " [29, 274, 105, 98, 275],\n",
              " [29, 274, 105, 98, 275, 155],\n",
              " [29, 274, 105, 98, 275, 155, 3],\n",
              " [29, 274, 105, 98, 275, 155, 3, 276],\n",
              " [29, 274, 105, 98, 275, 155, 3, 276, 59],\n",
              " [29, 274, 105, 98, 275, 155, 3, 276, 59, 277],\n",
              " [2, 21],\n",
              " [2, 21, 45],\n",
              " [2, 21, 45, 6],\n",
              " [2, 21, 45, 6, 278],\n",
              " [9, 10],\n",
              " [9, 10, 1],\n",
              " [9, 10, 1, 279],\n",
              " [2, 26],\n",
              " [2, 26, 5],\n",
              " [2, 26, 5, 280],\n",
              " [2, 26, 5, 280, 106],\n",
              " [2, 26, 5, 280, 106, 57],\n",
              " [22, 281],\n",
              " [22, 281, 101],\n",
              " [22, 281, 101, 15],\n",
              " [22, 281, 101, 15, 106],\n",
              " [18, 1],\n",
              " [18, 1, 107],\n",
              " [18, 1, 107, 156],\n",
              " [9, 30],\n",
              " [9, 30, 8],\n",
              " [9, 30, 8, 15],\n",
              " [9, 30, 8, 15, 106],\n",
              " [11, 8],\n",
              " [11, 8, 58],\n",
              " [11, 8, 58, 282],\n",
              " [11, 8, 58, 282, 16],\n",
              " [11, 8, 58, 282, 16, 3],\n",
              " [11, 8, 58, 282, 16, 3, 43],\n",
              " [4, 1],\n",
              " [4, 1, 283],\n",
              " [4, 1, 283, 284],\n",
              " [7, 2],\n",
              " [7, 2, 285],\n",
              " [7, 2, 285, 5],\n",
              " [7, 2, 285, 5, 108],\n",
              " [17, 8],\n",
              " [17, 8, 19],\n",
              " [17, 8, 19, 6],\n",
              " [17, 8, 19, 6, 157],\n",
              " [26, 1],\n",
              " [26, 1, 109],\n",
              " [26, 1, 109, 158],\n",
              " [38, 159],\n",
              " [38, 159, 2],\n",
              " [38, 159, 2, 21],\n",
              " [38, 159, 2, 21, 45],\n",
              " [38, 159, 2, 21, 45, 6],\n",
              " [38, 159, 2, 21, 45, 6, 110],\n",
              " [38, 159, 2, 21, 45, 6, 110, 111],\n",
              " [9, 31],\n",
              " [9, 31, 1],\n",
              " [9, 31, 1, 110],\n",
              " [160, 286],\n",
              " [160, 286, 14],\n",
              " [160, 286, 14, 287],\n",
              " [46, 145],\n",
              " [9, 47],\n",
              " [9, 47, 1],\n",
              " [2, 288],\n",
              " [2, 288, 109],\n",
              " [2, 288, 109, 158],\n",
              " [9, 60],\n",
              " [9, 60, 1],\n",
              " [9, 60, 1, 110],\n",
              " [2, 109],\n",
              " [2, 109, 289],\n",
              " [2, 109, 289, 14],\n",
              " [2, 109, 289, 14, 290],\n",
              " [48, 112],\n",
              " [4, 1],\n",
              " [4, 1, 72],\n",
              " [4, 1, 72, 6],\n",
              " [4, 1, 72, 6, 49],\n",
              " [4, 1, 72, 6, 49, 12],\n",
              " [4, 1, 72, 6, 49, 12, 5],\n",
              " [4, 1, 72, 6, 49, 12, 5, 102],\n",
              " [73, 17],\n",
              " [73, 17, 46],\n",
              " [73, 17, 46, 48],\n",
              " [161, 103],\n",
              " [161, 103, 58],\n",
              " [161, 103, 58, 3],\n",
              " [161, 103, 58, 3, 154],\n",
              " [9, 30],\n",
              " [71, 291],\n",
              " [71, 291, 162],\n",
              " [163, 32],\n",
              " [163, 32, 1],\n",
              " [163, 32, 1, 113],\n",
              " [32, 1],\n",
              " [32, 1, 111],\n",
              " [28, 8],\n",
              " [28, 8, 15],\n",
              " [28, 8, 15, 146],\n",
              " [25, 10],\n",
              " [25, 10, 61],\n",
              " [25, 10, 61, 94],\n",
              " [25, 10, 61, 94, 114],\n",
              " [17, 8],\n",
              " [17, 8, 22],\n",
              " [28, 47],\n",
              " [28, 47, 292],\n",
              " [293, 8],\n",
              " [293, 8, 294],\n",
              " [293, 8, 294, 74],\n",
              " [60, 1],\n",
              " [60, 1, 115],\n",
              " [60, 1, 115, 3],\n",
              " [60, 1, 115, 3, 295],\n",
              " [60, 1, 115, 3, 295, 75],\n",
              " [60, 1, 115, 3, 295, 75, 36],\n",
              " [296, 2],\n",
              " [296, 2, 164],\n",
              " [296, 2, 164, 11],\n",
              " [54, 165],\n",
              " [76, 166],\n",
              " [76, 166, 165],\n",
              " [167, 2],\n",
              " [167, 2, 21],\n",
              " [167, 2, 21, 168],\n",
              " [167, 2, 21, 168, 6],\n",
              " [167, 2, 21, 168, 6, 157],\n",
              " [167, 2, 21, 168, 6, 157, 17],\n",
              " [25, 297],\n",
              " [25, 297, 39],\n",
              " [25, 297, 39, 114],\n",
              " [7, 25],\n",
              " [7, 25, 10],\n",
              " [7, 25, 10, 298],\n",
              " [7, 25, 10, 298, 5],\n",
              " [7, 25, 10, 298, 5, 108],\n",
              " [60, 1],\n",
              " [60, 1, 116],\n",
              " [60, 1, 116, 15],\n",
              " [60, 1, 116, 15, 169],\n",
              " [38, 159],\n",
              " [38, 159, 2],\n",
              " [38, 159, 2, 31],\n",
              " [38, 159, 2, 31, 4],\n",
              " [38, 159, 2, 31, 4, 11],\n",
              " [38, 159, 2, 31, 4, 11, 77],\n",
              " [38, 159, 2, 31, 4, 11, 77, 170],\n",
              " [299, 73],\n",
              " [299, 73, 6],\n",
              " [299, 73, 6, 116],\n",
              " [299, 73, 6, 116, 99],\n",
              " [299, 73, 6, 116, 99, 30],\n",
              " [2, 31],\n",
              " [9, 10],\n",
              " [9, 10, 15],\n",
              " [9, 10, 15, 55],\n",
              " [9, 10, 15, 55, 171],\n",
              " [2, 300],\n",
              " [2, 300, 301],\n",
              " [2, 300, 301, 23],\n",
              " [2, 300, 301, 23, 302],\n",
              " [17, 46],\n",
              " [17, 46, 48],\n",
              " [25, 303],\n",
              " [25, 303, 16],\n",
              " [25, 303, 16, 3],\n",
              " [25, 303, 16, 3, 172],\n",
              " [2, 34],\n",
              " [2, 34, 3],\n",
              " [2, 34, 3, 172],\n",
              " [7, 50],\n",
              " [7, 50, 304],\n",
              " [7, 50, 304, 173],\n",
              " [4, 1],\n",
              " [4, 1, 13],\n",
              " [4, 1, 13, 6],\n",
              " [4, 1, 13, 6, 78],\n",
              " [4, 1, 13, 6, 78, 174],\n",
              " [175, 2],\n",
              " [175, 2, 56],\n",
              " [175, 2, 56, 70],\n",
              " [9, 305],\n",
              " [9, 305, 10],\n",
              " [9, 305, 10, 1],\n",
              " [9, 305, 10, 1, 70],\n",
              " [9, 305, 10, 1, 70, 176],\n",
              " [2, 67],\n",
              " [2, 67, 306],\n",
              " [2, 67, 306, 5],\n",
              " [2, 67, 306, 5, 177],\n",
              " [2, 67, 306, 5, 177, 307],\n",
              " [54, 8],\n",
              " [54, 8, 3],\n",
              " [54, 8, 3, 308],\n",
              " [309, 310],\n",
              " [134, 2],\n",
              " [134, 2, 34],\n",
              " [134, 2, 34, 44],\n",
              " [134, 2, 34, 44, 174],\n",
              " [7, 24],\n",
              " [7, 24, 8],\n",
              " [7, 24, 8, 5],\n",
              " [7, 24, 8, 5, 19],\n",
              " [7, 24, 8, 5, 19, 311],\n",
              " [9, 8],\n",
              " [9, 8, 15],\n",
              " [9, 8, 15, 35],\n",
              " [9, 8, 15, 35, 312],\n",
              " [2, 13],\n",
              " [2, 13, 177],\n",
              " [2, 13, 177, 14],\n",
              " [2, 13, 177, 14, 148],\n",
              " [4, 1],\n",
              " [4, 1, 78],\n",
              " [4, 1, 78, 51],\n",
              " [4, 1, 78, 51, 37],\n",
              " [2, 62],\n",
              " [2, 62, 6],\n",
              " [2, 62, 6, 78],\n",
              " [2, 62, 6, 78, 79],\n",
              " [2, 62, 6, 78, 79, 313],\n",
              " [17, 8],\n",
              " [17, 8, 5],\n",
              " [17, 8, 5, 22],\n",
              " [17, 8, 5, 22, 178],\n",
              " [18, 1],\n",
              " [4, 1],\n",
              " [4, 1, 26],\n",
              " [4, 1, 26, 314],\n",
              " [4, 1, 26, 314, 315],\n",
              " [7, 2],\n",
              " [7, 2, 26],\n",
              " [7, 2, 26, 5],\n",
              " [7, 2, 26, 5, 179],\n",
              " [9, 8],\n",
              " [9, 8, 15],\n",
              " [9, 8, 15, 316],\n",
              " [9, 8, 15, 316, 117],\n",
              " [97, 117],\n",
              " [97, 117, 8],\n",
              " [97, 117, 8, 317],\n",
              " [180, 117],\n",
              " [18, 1],\n",
              " [4, 1],\n",
              " [4, 1, 80],\n",
              " [4, 1, 80, 318],\n",
              " [4, 1, 80, 318, 12],\n",
              " [4, 1, 80, 318, 12, 319],\n",
              " [7, 51],\n",
              " [7, 51, 104],\n",
              " [20, 320],\n",
              " [20, 320, 34],\n",
              " [20, 320, 34, 17],\n",
              " [7, 20],\n",
              " [7, 20, 321],\n",
              " [7, 20, 321, 39],\n",
              " [7, 20, 321, 39, 181],\n",
              " [322, 10],\n",
              " [322, 10, 107],\n",
              " [322, 10, 107, 323],\n",
              " [2, 118],\n",
              " [2, 118, 25],\n",
              " [2, 118, 25, 10],\n",
              " [2, 118, 25, 10, 324],\n",
              " [4, 1],\n",
              " [4, 1, 13],\n",
              " [4, 1, 13, 325],\n",
              " [4, 1, 13, 325, 27],\n",
              " [7, 25],\n",
              " [7, 25, 10],\n",
              " [7, 25, 10, 39],\n",
              " [7, 25, 10, 39, 180],\n",
              " [4, 1],\n",
              " [4, 1, 182],\n",
              " [4, 1, 182, 326],\n",
              " [4, 1, 182, 326, 81],\n",
              " [4, 1, 182, 326, 81, 119],\n",
              " [2, 13],\n",
              " [2, 13, 119],\n",
              " [2, 13, 119, 16],\n",
              " [2, 13, 119, 16, 3],\n",
              " [2, 13, 119, 16, 3, 43],\n",
              " [52, 63],\n",
              " [4, 1],\n",
              " [4, 1, 183],\n",
              " [4, 1, 183, 184],\n",
              " [7, 2],\n",
              " [7, 2, 49],\n",
              " [7, 2, 49, 6],\n",
              " [7, 2, 49, 6, 3],\n",
              " [7, 2, 49, 6, 3, 185],\n",
              " [28, 82],\n",
              " [47, 327],\n",
              " [47, 327, 120],\n",
              " [47, 327, 120, 5],\n",
              " [47, 327, 120, 5, 121],\n",
              " [74, 2],\n",
              " [74, 2, 21],\n",
              " [74, 2, 21, 187],\n",
              " [74, 2, 21, 187, 6],\n",
              " [74, 2, 21, 187, 6, 188],\n",
              " [74, 2, 21, 187, 6, 188, 328],\n",
              " [64, 5],\n",
              " [64, 5, 22],\n",
              " [64, 5, 22, 329],\n",
              " [4, 1],\n",
              " [4, 1, 330],\n",
              " [4, 1, 330, 6],\n",
              " [4, 1, 330, 6, 83],\n",
              " [61, 3],\n",
              " [61, 3, 30],\n",
              " [54, 8],\n",
              " [54, 8, 15],\n",
              " [54, 8, 15, 35],\n",
              " [54, 8, 15, 35, 331],\n",
              " [2, 33],\n",
              " [2, 33, 13],\n",
              " [2, 33, 13, 332],\n",
              " [2, 33, 13, 332, 333],\n",
              " [24, 105],\n",
              " [24, 105, 19],\n",
              " [24, 105, 19, 334],\n",
              " [7, 2],\n",
              " [7, 2, 56],\n",
              " [7, 2, 56, 44],\n",
              " [7, 2, 56, 44, 83],\n",
              " [7, 2, 56, 44, 83, 27],\n",
              " [9, 8],\n",
              " [9, 8, 15],\n",
              " [9, 8, 15, 35],\n",
              " [9, 8, 15, 35, 335],\n",
              " [336, 50],\n",
              " [336, 50, 34],\n",
              " [336, 50, 34, 337],\n",
              " [48, 112],\n",
              " [18, 1],\n",
              " [10, 1],\n",
              " [10, 1, 189],\n",
              " [10, 1, 189, 29],\n",
              " [10, 1, 189, 29, 55],\n",
              " [7, 2],\n",
              " [7, 2, 21],\n",
              " [161, 49],\n",
              " [161, 49, 149],\n",
              " [17, 46],\n",
              " [17, 46, 65],\n",
              " [2, 31],\n",
              " [2, 31, 190],\n",
              " [2, 31, 190, 191],\n",
              " [19, 338],\n",
              " [32, 1],\n",
              " [32, 1, 192],\n",
              " [32, 1],\n",
              " [32, 1, 113],\n",
              " [80, 339],\n",
              " [1, 27],\n",
              " [22, 36],\n",
              " [22, 36],\n",
              " [22, 36, 340],\n",
              " [22, 36, 340, 341],\n",
              " [18, 1],\n",
              " [26, 5],\n",
              " [26, 5, 19],\n",
              " [26, 5, 19, 37],\n",
              " [1, 27],\n",
              " [1, 27, 122],\n",
              " [122, 32],\n",
              " [122, 32, 1],\n",
              " [122, 32, 1, 57],\n",
              " [73, 32],\n",
              " [73, 32, 1],\n",
              " [28, 84],\n",
              " [28, 84, 15],\n",
              " [28, 84, 15, 37],\n",
              " [11, 84],\n",
              " [11, 84, 22],\n",
              " [11, 84, 22, 14],\n",
              " [11, 84, 22, 14, 342],\n",
              " [60, 1],\n",
              " [60, 1, 4],\n",
              " [60, 1, 4, 343],\n",
              " [60, 1, 4, 343, 344],\n",
              " [38, 33],\n",
              " [38, 33, 67],\n",
              " [38, 33, 67, 345],\n",
              " [66, 346],\n",
              " [66, 346, 8],\n",
              " [66, 346, 8, 347],\n",
              " [2, 118],\n",
              " [9, 30],\n",
              " [9, 30, 4],\n",
              " [9, 30, 4, 1],\n",
              " [9, 30, 4, 1, 193],\n",
              " [9, 30, 4, 1, 193, 194],\n",
              " [71, 348],\n",
              " [71, 348, 162],\n",
              " [17, 8],\n",
              " [17, 8, 195],\n",
              " [2, 62],\n",
              " [2, 62, 6],\n",
              " [2, 62, 6, 194],\n",
              " [2, 62, 6, 194, 349],\n",
              " [52, 63],\n",
              " [4, 1],\n",
              " [4, 1, 13],\n",
              " [4, 1, 13, 350],\n",
              " [7, 11],\n",
              " [7, 11, 8],\n",
              " [7, 11, 8, 65],\n",
              " [9, 4],\n",
              " [9, 4, 1],\n",
              " [9, 4, 1, 13],\n",
              " [9, 4, 1, 13, 6],\n",
              " [9, 4, 1, 13, 6, 196],\n",
              " [85, 351],\n",
              " [85, 351, 14],\n",
              " [85, 351, 14, 352],\n",
              " [4, 1],\n",
              " [4, 1, 196],\n",
              " [4, 1, 196, 82],\n",
              " [5, 59],\n",
              " [5, 59, 120],\n",
              " [5, 59, 120, 5],\n",
              " [5, 59, 120, 5, 121],\n",
              " [64, 48],\n",
              " [4, 1],\n",
              " [4, 1, 115],\n",
              " [4, 1, 115, 353],\n",
              " [4, 1, 115, 353, 197],\n",
              " [7, 2],\n",
              " [7, 2, 34],\n",
              " [7, 2, 34, 198],\n",
              " [9, 8],\n",
              " [9, 8, 15],\n",
              " [9, 8, 15, 35],\n",
              " [9, 8, 15, 35, 199],\n",
              " [200, 14],\n",
              " [200, 14, 354],\n",
              " [200, 14, 354, 355],\n",
              " [19, 356],\n",
              " [18, 1],\n",
              " [9, 123],\n",
              " [9, 123, 4],\n",
              " [9, 123, 4, 1],\n",
              " [9, 123, 4, 1, 53],\n",
              " [2, 53],\n",
              " [2, 53, 357],\n",
              " [2, 53, 357, 358],\n",
              " [28, 4],\n",
              " [28, 4, 1],\n",
              " [28, 4, 1, 13],\n",
              " [28, 4, 1, 13, 11],\n",
              " [2, 34],\n",
              " [2, 34, 11],\n",
              " [40, 27],\n",
              " [163, 2],\n",
              " [163, 2, 26],\n",
              " [163, 2, 26, 6],\n",
              " [163, 2, 26, 6, 49],\n",
              " [163, 2, 26, 6, 49, 176],\n",
              " [359, 6],\n",
              " [359, 6, 1],\n",
              " [359, 6, 1, 360],\n",
              " [73, 122],\n",
              " [10, 1],\n",
              " [10, 1, 45],\n",
              " [10, 1, 45, 6],\n",
              " [10, 1, 45, 6, 3],\n",
              " [10, 1, 45, 6, 3, 124],\n",
              " [7, 2],\n",
              " [7, 2, 21],\n",
              " [7, 2, 21, 181],\n",
              " [54, 361],\n",
              " [54, 361, 8],\n",
              " [54, 361, 8, 143],\n",
              " [2, 362],\n",
              " [2, 362, 363],\n",
              " [2, 362, 363, 14],\n",
              " [2, 362, 363, 14, 364],\n",
              " [125, 11],\n",
              " [125, 11, 31],\n",
              " [125, 11, 31, 126],\n",
              " [125, 11, 31, 126, 65],\n",
              " [7, 365],\n",
              " [7, 365, 366],\n",
              " [7, 365, 366, 6],\n",
              " [7, 365, 366, 6, 11],\n",
              " [9, 31],\n",
              " [9, 31, 1],\n",
              " [9, 31, 1, 367],\n",
              " [160, 5],\n",
              " [160, 5, 368],\n",
              " [160, 5, 368, 369],\n",
              " [48, 17],\n",
              " [48, 17, 31],\n",
              " [48, 17, 31, 370],\n",
              " [48, 17, 31, 370, 22],\n",
              " [74, 12],\n",
              " [74, 12, 3],\n",
              " [74, 12, 3, 371],\n",
              " [4, 1],\n",
              " [4, 1, 86],\n",
              " [4, 1, 86, 5],\n",
              " [4, 1, 86, 5, 372],\n",
              " [7, 373],\n",
              " [7, 373, 87],\n",
              " [7, 373, 87, 38],\n",
              " [7, 373, 87, 38, 5],\n",
              " [7, 373, 87, 38, 5, 374],\n",
              " [38, 58],\n",
              " [38, 58, 61],\n",
              " [38, 58, 61, 168],\n",
              " [38, 58, 61, 168, 6],\n",
              " [38, 58, 61, 168, 6, 375],\n",
              " [9, 30],\n",
              " [9, 30, 41],\n",
              " [9, 30, 41, 2],\n",
              " [9, 30, 41, 2, 376],\n",
              " [9, 30, 41, 2, 376, 1],\n",
              " [9, 30, 41, 2, 376, 1, 88],\n",
              " [71, 377],\n",
              " [71, 377, 201],\n",
              " [71, 377, 201, 126],\n",
              " [71, 377, 201, 126, 19],\n",
              " [202, 32],\n",
              " [202, 32, 1],\n",
              " [202, 32, 1, 113],\n",
              " [32, 1],\n",
              " [32, 1, 111],\n",
              " [4, 1],\n",
              " [4, 1, 13],\n",
              " [4, 1, 13, 203],\n",
              " [7, 11],\n",
              " [7, 11, 89],\n",
              " [7, 11, 89, 40],\n",
              " [7, 11, 89, 40, 378],\n",
              " [9, 4],\n",
              " [9, 4, 1],\n",
              " [9, 4, 1, 379],\n",
              " [85, 204],\n",
              " [85, 204, 14],\n",
              " [85, 204, 14, 205],\n",
              " [17, 46],\n",
              " [17, 46, 127],\n",
              " [18, 1],\n",
              " [4, 1],\n",
              " [4, 1, 80],\n",
              " [4, 1, 80, 380],\n",
              " [4, 1, 80, 380, 206],\n",
              " [2, 381],\n",
              " [2, 381, 207],\n",
              " [2, 381, 207, 208],\n",
              " [90, 186],\n",
              " [1, 382],\n",
              " [1, 382, 128],\n",
              " [1, 382, 128, 107],\n",
              " [1, 382, 128, 107, 156],\n",
              " [1, 382, 128, 107, 156, 209],\n",
              " [7, 383],\n",
              " [7, 383, 8],\n",
              " [7, 383, 8, 5],\n",
              " [7, 383, 8, 5, 19],\n",
              " [7, 383, 8, 5, 19, 152],\n",
              " [9, 384],\n",
              " [9, 384, 4],\n",
              " [9, 384, 4, 1],\n",
              " [9, 384, 4, 1, 26],\n",
              " [2, 56],\n",
              " [2, 56, 385],\n",
              " [2, 56, 385, 14],\n",
              " [2, 56, 385, 14, 386],\n",
              " [26, 1],\n",
              " [26, 1, 387],\n",
              " [26, 1, 387, 210],\n",
              " [7, 388],\n",
              " [7, 388, 389],\n",
              " [7, 388, 389, 12],\n",
              " [7, 388, 389, 12, 65],\n",
              " [1, 41],\n",
              " [1, 41, 390],\n",
              " [1, 41, 390, 198],\n",
              " [391, 211],\n",
              " [391, 211, 37],\n",
              " [1, 91],\n",
              " [1, 91, 41],\n",
              " [18, 1],\n",
              " [18, 1, 12],\n",
              " [18, 1, 12, 3],\n",
              " [18, 1, 12, 3, 392],\n",
              " [28, 4],\n",
              " [28, 4, 1],\n",
              " [28, 4, 1, 393],\n",
              " [28, 4, 1, 393, 101],\n",
              " [28, 4, 1, 393, 101, 394],\n",
              " [2, 193],\n",
              " [2, 193, 49],\n",
              " [2, 193, 49, 12],\n",
              " [2, 193, 49, 12, 5],\n",
              " [2, 193, 49, 12, 5, 102],\n",
              " [17, 89],\n",
              " [17, 89, 40],\n",
              " [17, 89, 40, 27],\n",
              " [395, 396],\n",
              " [395, 396, 8],\n",
              " [395, 396, 8, 167],\n",
              " [7, 14],\n",
              " [7, 14, 212],\n",
              " [7, 14, 212, 397],\n",
              " [7, 14, 212, 397, 40],\n",
              " [4, 1],\n",
              " [4, 1, 129],\n",
              " [4, 1, 129, 398],\n",
              " [66, 79],\n",
              " [66, 79, 399],\n",
              " [11, 89],\n",
              " [11, 89, 400],\n",
              " [11, 89, 400, 3],\n",
              " [11, 89, 400, 3, 401],\n",
              " [7, 14],\n",
              " [7, 14, 402],\n",
              " [7, 14, 402, 403],\n",
              " [26, 1],\n",
              " [26, 1, 404],\n",
              " [26, 1, 404, 213],\n",
              " [5, 59],\n",
              " [5, 59, 120],\n",
              " [5, 59, 120, 7],\n",
              " [60, 1],\n",
              " [60, 1, 13],\n",
              " [60, 1, 13, 11],\n",
              " [7, 50],\n",
              " [7, 50, 39],\n",
              " [7, 50, 39, 405],\n",
              " [2, 41],\n",
              " [2, 41, 62],\n",
              " [2, 41, 62, 11],\n",
              " [2, 41, 62, 11, 406],\n",
              " [1, 91],\n",
              " [1, 91, 41],\n",
              " [4, 1],\n",
              " [4, 1, 13],\n",
              " [4, 1, 13, 130],\n",
              " [4, 1, 13, 130, 407],\n",
              " [7, 2],\n",
              " [7, 2, 72],\n",
              " [7, 2, 72, 6],\n",
              " [7, 2, 72, 6, 128],\n",
              " [7, 2, 72, 6, 128, 408],\n",
              " [64, 5],\n",
              " [64, 5, 22],\n",
              " [64, 5, 22, 112],\n",
              " [50, 5],\n",
              " [50, 5, 127],\n",
              " [50, 5, 127, 214],\n",
              " [2, 118],\n",
              " [409, 98],\n",
              " [409, 98, 410],\n",
              " [409, 98, 410, 213],\n",
              " [409, 98, 410, 213, 51],\n",
              " [409, 98, 410, 213, 51, 37],\n",
              " [409, 98, 410, 213, 51, 37, 12],\n",
              " [409, 98, 410, 213, 51, 37, 12, 411],\n",
              " [409, 98, 410, 213, 51, 37, 12, 411, 412],\n",
              " [3, 92],\n",
              " [3, 92, 413],\n",
              " [3, 92, 413, 414],\n",
              " [3, 92, 413, 414, 415],\n",
              " [3, 92, 413, 414, 415, 184],\n",
              " [3, 92, 413, 414, 415, 184, 16],\n",
              " [3, 92, 413, 414, 415, 184, 16, 416],\n",
              " [3, 92, 413, 414, 415, 184, 16, 416, 417],\n",
              " [3, 92, 413, 414, 415, 184, 16, 416, 417, 151],\n",
              " [42, 418],\n",
              " [42, 418, 76],\n",
              " [42, 418, 76, 55],\n",
              " [42, 418, 76, 55, 171],\n",
              " [42, 418, 76, 55, 171, 215],\n",
              " [42, 418, 76, 55, 171, 215, 3],\n",
              " [42, 418, 76, 55, 171, 215, 3, 419],\n",
              " [42, 418, 76, 55, 171, 215, 3, 419, 420],\n",
              " [42, 418, 76, 55, 171, 215, 3, 419, 420, 139],\n",
              " [4, 1],\n",
              " [4, 1, 421],\n",
              " [4, 1, 421, 422],\n",
              " [4, 1, 421, 422, 42],\n",
              " [4, 1, 421, 422, 42, 423],\n",
              " [4, 1, 421, 422, 42, 423, 3],\n",
              " [4, 1, 421, 422, 42, 423, 3, 424],\n",
              " [4, 1, 421, 422, 42, 423, 3, 424, 75],\n",
              " [4, 1, 421, 422, 42, 423, 3, 424, 75, 36],\n",
              " [24, 425],\n",
              " [24, 425, 3],\n",
              " [24, 425, 3, 426],\n",
              " [24, 425, 3, 426, 427],\n",
              " [24, 425, 3, 426, 427, 96],\n",
              " [24, 425, 3, 426, 427, 96, 3],\n",
              " [24, 425, 3, 426, 427, 96, 3, 199],\n",
              " [24, 425, 3, 426, 427, 96, 3, 199, 16],\n",
              " [24, 425, 3, 426, 427, 96, 3, 199, 16, 211],\n",
              " [24, 425, 3, 426, 427, 96, 3, 199, 16, 211, 37],\n",
              " [216, 187],\n",
              " [216, 187, 6],\n",
              " [216, 187, 6, 428],\n",
              " [216, 187, 6, 428, 97],\n",
              " [216, 187, 6, 428, 97, 429],\n",
              " [216, 187, 6, 428, 97, 429, 430],\n",
              " [216, 187, 6, 428, 97, 429, 430, 70],\n",
              " [216, 187, 6, 428, 97, 429, 430, 70, 51],\n",
              " [216, 187, 6, 428, 97, 429, 430, 70, 51, 36],\n",
              " [42, 431],\n",
              " [42, 431, 88],\n",
              " [42, 431, 88, 217],\n",
              " [42, 431, 88, 217, 68],\n",
              " [42, 431, 88, 217, 68, 432],\n",
              " [42, 431, 88, 217, 68, 432, 136],\n",
              " [42, 431, 88, 217, 68, 432, 136, 14],\n",
              " [42, 431, 88, 217, 68, 432, 136, 14, 433],\n",
              " [42, 431, 88, 217, 68, 432, 136, 14, 433, 191],\n",
              " [216, 434],\n",
              " [216, 434, 47],\n",
              " [216, 434, 47, 435],\n",
              " [216, 434, 47, 435, 5],\n",
              " [216, 434, 47, 435, 5, 436],\n",
              " [216, 434, 47, 435, 5, 436, 218],\n",
              " [216, 434, 47, 435, 5, 436, 218, 29],\n",
              " [216, 434, 47, 435, 5, 436, 218, 29, 144],\n",
              " [2, 86],\n",
              " [2, 86, 6],\n",
              " [2, 86, 6, 116],\n",
              " [2, 86, 6, 116, 29],\n",
              " [2, 86, 6, 116, 29, 150],\n",
              " [2, 86, 6, 116, 29, 150, 79],\n",
              " [2, 86, 6, 116, 29, 150, 79, 3],\n",
              " [2, 86, 6, 116, 29, 150, 79, 3, 437],\n",
              " [2, 86, 6, 116, 29, 150, 79, 3, 437, 57],\n",
              " [24, 131],\n",
              " [24, 131, 89],\n",
              " [24, 131, 89, 438],\n",
              " [24, 131, 89, 438, 439],\n",
              " [24, 131, 89, 438, 439, 25],\n",
              " [24, 131, 89, 438, 439, 25, 10],\n",
              " [24, 131, 89, 438, 439, 25, 10, 16],\n",
              " [24, 131, 89, 438, 439, 25, 10, 16, 86],\n",
              " [23, 440],\n",
              " [23, 440, 10],\n",
              " [23, 440, 10, 132],\n",
              " [23, 440, 10, 132, 6],\n",
              " [23, 440, 10, 132, 6, 441],\n",
              " [23, 440, 10, 132, 6, 441, 76],\n",
              " [23, 440, 10, 132, 6, 441, 76, 442],\n",
              " [23, 440, 10, 132, 6, 441, 76, 442, 95],\n",
              " [23, 440, 10, 132, 6, 441, 76, 442, 95, 443],\n",
              " [42, 444],\n",
              " [42, 444, 6],\n",
              " [42, 444, 6, 190],\n",
              " [42, 444, 6, 190, 3],\n",
              " [42, 444, 6, 190, 3, 445],\n",
              " [42, 444, 6, 190, 3, 445, 6],\n",
              " [42, 444, 6, 190, 3, 445, 6, 3],\n",
              " [42, 444, 6, 190, 3, 445, 6, 3, 83],\n",
              " [42, 444, 6, 190, 3, 445, 6, 3, 83, 446],\n",
              " [28, 10],\n",
              " [28, 10, 15],\n",
              " [28, 10, 15, 206],\n",
              " [28, 10, 15, 206, 45],\n",
              " [25, 10],\n",
              " [25, 10, 45],\n",
              " [25, 10, 45, 114],\n",
              " [9, 447],\n",
              " [9, 447, 8],\n",
              " [9, 447, 8, 15],\n",
              " [9, 447, 8, 15, 35],\n",
              " [2, 56],\n",
              " [2, 56, 448],\n",
              " [2, 56, 448, 135],\n",
              " [40, 27],\n",
              " [40, 27, 87],\n",
              " [40, 27, 87, 449],\n",
              " [4, 1],\n",
              " [4, 1, 219],\n",
              " [4, 1, 219, 82],\n",
              " [7, 2],\n",
              " [7, 2, 129],\n",
              " [7, 2, 129, 450],\n",
              " [90, 451],\n",
              " [129, 220],\n",
              " [129, 220, 202],\n",
              " [4, 1],\n",
              " [4, 1, 452],\n",
              " [4, 1, 452, 221],\n",
              " [7, 50],\n",
              " [7, 50, 23],\n",
              " [7, 50, 23, 35],\n",
              " [7, 50, 23, 35, 214],\n",
              " [453, 27],\n",
              " [9, 133],\n",
              " [9, 133, 26],\n",
              " [9, 133, 26, 1],\n",
              " [9, 133, 26, 1, 454],\n",
              " [5, 59],\n",
              " [5, 59, 455],\n",
              " [5, 59, 455, 93],\n",
              " [5, 59, 455, 93, 14],\n",
              " [5, 59, 455, 93, 14, 456],\n",
              " [64, 33],\n",
              " [64, 33, 125],\n",
              " [18, 1],\n",
              " [4, 1],\n",
              " [4, 1, 72],\n",
              " [4, 1, 72, 6],\n",
              " [4, 1, 72, 6, 183],\n",
              " [4, 1, 72, 6, 183, 16],\n",
              " [4, 1, 72, 6, 183, 16, 457],\n",
              " [7, 87],\n",
              " [7, 87, 23],\n",
              " [7, 87, 23, 458],\n",
              " [7, 87, 23, 458, 459],\n",
              " [1, 31],\n",
              " [1, 31, 460],\n",
              " [1, 31, 460, 173],\n",
              " [18, 1],\n",
              " [18, 1, 12],\n",
              " [18, 1, 12, 461],\n",
              " [18, 1, 12, 461, 16],\n",
              " [18, 1, 12, 461, 16, 40],\n",
              " [4, 1],\n",
              " [4, 1, 53],\n",
              " [4, 1, 53, 462],\n",
              " [7, 12],\n",
              " [7, 12, 61],\n",
              " [7, 12, 61, 23],\n",
              " [7, 12, 61, 23, 133],\n",
              " [90, 463],\n",
              " [11, 464],\n",
              " [11, 464, 465],\n",
              " [11, 464, 465, 466],\n",
              " [7, 14],\n",
              " [7, 14, 197],\n",
              " [7, 14, 197, 467],\n",
              " [4, 1],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we know, for input all inputs must have same size -----> Padding"
      ],
      "metadata": {
        "id": "FDHkGmz2mOh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length = []\n",
        "for i in input_sents:\n",
        "  length.append(len(i))\n",
        "\n",
        "max_len = max(length)"
      ],
      "metadata": {
        "id": "uhKQgNV8lbau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_input = pad_sequences(input_sents, maxlen= max_len, padding='pre')"
      ],
      "metadata": {
        "id": "UgRS07ILm6LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttm8CnQWny8m",
        "outputId": "87e9766d-b92b-4e49-87c5-cc6fe3ca9ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0, 227,  28],\n",
              "       [  0,   0,   0, ..., 227,  28,  10],\n",
              "       [  0,   0,   0, ...,  28,  10,   1],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   5,  59,  12],\n",
              "       [  0,   0,   0, ...,  59,  12, 579],\n",
              "       [  0,   0,   0, ...,   0, 220, 580]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3mp6Ekun0VD",
        "outputId": "3ecd7caa-d9b4-478b-ab01-1e54e836f7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1341, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_input[:,:-1]\n",
        "\n",
        "y = padded_input[:,-1]"
      ],
      "metadata": {
        "id": "z5ovu1A5n48x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gju2ODqYor6q",
        "outputId": "67517c5f-e704-4901-8903-a96fea378d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1341,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now convert each word into ONE-HOT-ENCODING\n",
        "\n",
        "for input"
      ],
      "metadata": {
        "id": "_nxCf4hjqAlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(y, num_classes=581)"
      ],
      "metadata": {
        "id": "0JVqgVrQpGwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn7S49CMpGsk",
        "outputId": "bf498d74-af5d-4802-9b13-ee699eb0acea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0, 227], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Architecture"
      ],
      "metadata": {
        "id": "q2JOS_D2s4oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM"
      ],
      "metadata": {
        "id": "p-XGWnLIpGqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "6M2bHoWox4Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tk.word_index) + 1"
      ],
      "metadata": {
        "id": "qGKs2wjE2KZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xcEnpoJ2Of4",
        "outputId": "309ed24c-134c-4dda-883f-5b9560ade33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "581"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using Embedding layer for converting sparse vector into Dense vector, size = 100"
      ],
      "metadata": {
        "id": "b0gxYB7DyZPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab_size = 582 (example), embedding_dim = 100, input_length = 10\n",
        "model.add(Embedding(total_words, output_dim=100, input_length=10))\n",
        "model.add(LSTM(200))\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "metadata": {
        "id": "xsCI1dWLx7GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "5NkfeXmex88h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Build the model manually\n",
        "model.build(input_shape=(None, 10))  # batch size = None, sequence length = 10\n"
      ],
      "metadata": {
        "id": "lejwLY9XyBpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "4XlcqTXjxvek",
        "outputId": "12de341b-4556-49a9-a170-98bc00ad521a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m58,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m240,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m581\u001b[0m)            │       \u001b[38;5;34m116,781\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">58,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">581</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">116,781</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m415,681\u001b[0m (1.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">415,681</span> (1.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m415,681\u001b[0m (1.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">415,681</span> (1.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku419cnmyGq1",
        "outputId": "e124d949-4df7-49ff-9f9b-9e17e68109e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.0542 - loss: 6.2223\n",
            "Epoch 2/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0599 - loss: 5.7293\n",
            "Epoch 3/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.0801 - loss: 5.5581\n",
            "Epoch 4/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.0838 - loss: 5.4011\n",
            "Epoch 5/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1096 - loss: 5.0942\n",
            "Epoch 6/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.1362 - loss: 4.9121\n",
            "Epoch 7/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.1377 - loss: 4.8436\n",
            "Epoch 8/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1426 - loss: 4.6849\n",
            "Epoch 9/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1732 - loss: 4.4702\n",
            "Epoch 10/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1780 - loss: 4.3117\n",
            "Epoch 11/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.1931 - loss: 4.1041\n",
            "Epoch 12/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.2060 - loss: 3.9017\n",
            "Epoch 13/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1927 - loss: 3.7356\n",
            "Epoch 14/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2486 - loss: 3.4491\n",
            "Epoch 15/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.2904 - loss: 3.2965\n",
            "Epoch 16/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.3158 - loss: 3.1146\n",
            "Epoch 17/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.3754 - loss: 2.9030\n",
            "Epoch 18/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.4299 - loss: 2.6883\n",
            "Epoch 19/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4595 - loss: 2.5219\n",
            "Epoch 20/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5122 - loss: 2.3761\n",
            "Epoch 21/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5288 - loss: 2.2154\n",
            "Epoch 22/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5661 - loss: 2.0711\n",
            "Epoch 23/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.5891 - loss: 1.9536\n",
            "Epoch 24/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.6085 - loss: 1.8397\n",
            "Epoch 25/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.6427 - loss: 1.7168\n",
            "Epoch 26/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6822 - loss: 1.6141\n",
            "Epoch 27/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.6995 - loss: 1.4908\n",
            "Epoch 28/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.6973 - loss: 1.4511\n",
            "Epoch 29/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.7174 - loss: 1.3890\n",
            "Epoch 30/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7239 - loss: 1.2808\n",
            "Epoch 31/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7290 - loss: 1.2677\n",
            "Epoch 32/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7276 - loss: 1.1855\n",
            "Epoch 33/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7349 - loss: 1.1423\n",
            "Epoch 34/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7420 - loss: 1.0948\n",
            "Epoch 35/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7553 - loss: 1.0720\n",
            "Epoch 36/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7604 - loss: 1.0111\n",
            "Epoch 37/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7757 - loss: 0.9453\n",
            "Epoch 38/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7785 - loss: 0.9075\n",
            "Epoch 39/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7720 - loss: 0.9052\n",
            "Epoch 40/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7610 - loss: 0.8900\n",
            "Epoch 41/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7622 - loss: 0.8779\n",
            "Epoch 42/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7746 - loss: 0.8434\n",
            "Epoch 43/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7661 - loss: 0.8169\n",
            "Epoch 44/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7848 - loss: 0.7519\n",
            "Epoch 45/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7657 - loss: 0.7858\n",
            "Epoch 46/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7659 - loss: 0.7805\n",
            "Epoch 47/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7852 - loss: 0.7568\n",
            "Epoch 48/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7890 - loss: 0.7381\n",
            "Epoch 49/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7714 - loss: 0.7431\n",
            "Epoch 50/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7878 - loss: 0.6765\n",
            "Epoch 51/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8044 - loss: 0.6274\n",
            "Epoch 52/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7959 - loss: 0.6861\n",
            "Epoch 53/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7761 - loss: 0.6872\n",
            "Epoch 54/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7794 - loss: 0.6564\n",
            "Epoch 55/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7747 - loss: 0.6875\n",
            "Epoch 56/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7937 - loss: 0.5904\n",
            "Epoch 57/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7684 - loss: 0.6862\n",
            "Epoch 58/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7758 - loss: 0.6458\n",
            "Epoch 59/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.7576 - loss: 0.6754\n",
            "Epoch 60/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7794 - loss: 0.6685\n",
            "Epoch 61/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7912 - loss: 0.6276\n",
            "Epoch 62/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7820 - loss: 0.6304\n",
            "Epoch 63/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7933 - loss: 0.6265\n",
            "Epoch 64/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7828 - loss: 0.6313\n",
            "Epoch 65/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7736 - loss: 0.6205\n",
            "Epoch 66/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7925 - loss: 0.5965\n",
            "Epoch 67/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7670 - loss: 0.6489\n",
            "Epoch 68/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7771 - loss: 0.6473\n",
            "Epoch 69/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7681 - loss: 0.6261\n",
            "Epoch 70/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7871 - loss: 0.5974\n",
            "Epoch 71/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.7973 - loss: 0.5557\n",
            "Epoch 72/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8055 - loss: 0.5562\n",
            "Epoch 73/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7794 - loss: 0.6129\n",
            "Epoch 74/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7805 - loss: 0.6299\n",
            "Epoch 75/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7826 - loss: 0.5936\n",
            "Epoch 76/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7888 - loss: 0.5455\n",
            "Epoch 77/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.7955 - loss: 0.5758\n",
            "Epoch 78/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7989 - loss: 0.5432\n",
            "Epoch 79/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7746 - loss: 0.5936\n",
            "Epoch 80/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.7912 - loss: 0.5646\n",
            "Epoch 81/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7840 - loss: 0.5755\n",
            "Epoch 82/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7793 - loss: 0.5835\n",
            "Epoch 83/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.7903 - loss: 0.5449\n",
            "Epoch 84/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7879 - loss: 0.5654\n",
            "Epoch 85/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8011 - loss: 0.5583\n",
            "Epoch 86/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.7859 - loss: 0.5667\n",
            "Epoch 87/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7754 - loss: 0.5683\n",
            "Epoch 88/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7846 - loss: 0.5627\n",
            "Epoch 89/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.7913 - loss: 0.5298\n",
            "Epoch 90/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7715 - loss: 0.5753\n",
            "Epoch 91/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7891 - loss: 0.5669\n",
            "Epoch 92/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.7943 - loss: 0.5441\n",
            "Epoch 93/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.7910 - loss: 0.5686\n",
            "Epoch 94/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.7812 - loss: 0.5766\n",
            "Epoch 95/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7970 - loss: 0.5468\n",
            "Epoch 96/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7825 - loss: 0.5573\n",
            "Epoch 97/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8008 - loss: 0.5373\n",
            "Epoch 98/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7937 - loss: 0.5437\n",
            "Epoch 99/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7927 - loss: 0.5326\n",
            "Epoch 100/100\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7809 - loss: 0.5465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f10d3f4fc90>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Do prediction"
      ],
      "metadata": {
        "id": "npCz2IAZ3sLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "  for i in range(5):\n",
        "\n",
        "    # Tokenize\n",
        "    token_text = tk.texts_to_sequences([text])[0]\n",
        "\n",
        "    # Padding\n",
        "    padded_token_text = pad_sequences([token_text], maxlen=10,padding='pre')\n",
        "\n",
        "    # predict\n",
        "    # it give me probability for all words--> ki next kon sa word ho sakta hai\n",
        "    pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "    # now us word ko nikalo jiska probability sabse jyada hai\n",
        "    for word,index in tk.word_index.items():\n",
        "      if index == pos:\n",
        "        text = text + ' ' + word\n",
        "        print(text)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jda9jv--yI4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"hey how are\"\n",
        "text2 = \"are you a\"\n",
        "text3 = \"get lost i dont want to\""
      ],
      "metadata": {
        "id": "WavsUSiKN_Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwiZKNVP5aZC",
        "outputId": "bca9da82-b124-4d98-d705-902b0cdfbb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "hey how are your\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "hey how are your classes\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "hey how are your classes going\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "hey how are your classes going to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "hey how are your classes going to the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsAHrdUz8hr9",
        "outputId": "fd96470a-0f5f-4f9c-ab18-9b64b3a4e0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "are you a day\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "are you a day for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "are you a day for walks\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "are you a day for walks for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "are you a day for walks for last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(text3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zl7IS4K8jBb",
        "outputId": "b18906fd-5184-4715-b106-42138ecd16d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "get lost i dont want to the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "get lost i dont want to the gym\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "get lost i dont want to the gym almost\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "get lost i dont want to the gym almost every\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "get lost i dont want to the gym almost every morning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7h7gW5H39ITI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}